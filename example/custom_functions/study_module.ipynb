{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This module is developed not only to annotate the shapes of tensors of DL models, <br/>\n",
    "but also to test the annotated shapes.\n",
    "\n",
    "Therefore, the default test algorithms expects the inputs with `.shape: Set[int]` field.\n",
    "I expect, we can customize 3 functions. They are:\n",
    "\n",
    "- get_meta_annotations\n",
    "- generate_meta_dict\n",
    "- push_execution_result\n",
    "\n",
    "You might feel the implementations of the first two are kind of advanced.\n",
    "Since I do the `Microwise Development`, it would be easy to track the mechanism.\n",
    "\n",
    "To use the `test_meta_dict`, we need to prepare two things.\n",
    "\n",
    "- comparison expressions\n",
    "- arguments in the expressions\n",
    "\n",
    "You would modify the functions to manipulate the algorithm to get those values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Example\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding of Types and Functions\n",
    "\n",
    "First, look through to `MetaDict_`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from crimson.executable_types_beta.utils import (\n",
    "    get_meta_annotations,\n",
    "    generate_meta_dict,\n",
    "    delegate_func_returning_args_details\n",
    ")\n",
    "from crimson.types_beta.addon import TypesPack\n",
    "from crimson.executable_types_beta.mock import TensorMock\n",
    "from crimson.executable_types_beta.executor import AnnotationExecutor\n",
    "from crimson.executable_types_beta.test import test_meta_dict\n",
    "from typing import List\n",
    "from crimson.executable_types_beta.types import *\n",
    "from inspect import currentframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "array1 = TensorMock.ones((4, 6))\n",
    "array2 = TensorMock.ones((8, 10))\n",
    "array3 = TensorMock.ones((4, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'array1': ['b', 'c'],\n",
       " 'array2': ['d == 2*b', 'e == b+2*c'],\n",
       " 'array3': None,\n",
       " 'return': ['b', 'f == 3 * b']}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def func(\n",
    "    array1: TensorMock[List, \"b\", \"c\"], \n",
    "    array2: TensorMock[List, \"d == 2*b\", \"e == b+2*c\"],\n",
    "    array3: TensorMock\n",
    ") -> TensorMock[List, \"b\", \"f == 3 * b\"]:\n",
    "    array4 = TensorMock.ones((4, 8))\n",
    "    return array4\n",
    "\n",
    "get_meta_annotations(func=func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "output, arg_details, model_fields = delegate_func_returning_args_details(\n",
    "    func=func,\n",
    "    env=currentframe().f_locals,\n",
    "\t**{\n",
    "        'array1':array1,\n",
    "        'array2':array2,\n",
    "        'array3':array3,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 1, 1, 1, 1, 1, 1, 1],\n",
       " [1, 1, 1, 1, 1, 1, 1, 1],\n",
       " [1, 1, 1, 1, 1, 1, 1, 1],\n",
       " [1, 1, 1, 1, 1, 1, 1, 1]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'array1': [[1, 1, 1, 1, 1, 1],\n",
       "  [1, 1, 1, 1, 1, 1],\n",
       "  [1, 1, 1, 1, 1, 1],\n",
       "  [1, 1, 1, 1, 1, 1]],\n",
       " 'array2': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       " 'array3': [[1, 1, 1, 1, 1, 1, 1, 1],\n",
       "  [1, 1, 1, 1, 1, 1, 1, 1],\n",
       "  [1, 1, 1, 1, 1, 1, 1, 1],\n",
       "  [1, 1, 1, 1, 1, 1, 1, 1]],\n",
       " 'return': [[1, 1, 1, 1, 1, 1, 1, 1],\n",
       "  [1, 1, 1, 1, 1, 1, 1, 1],\n",
       "  [1, 1, 1, 1, 1, 1, 1, 1],\n",
       "  [1, 1, 1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arg_details: ArgsDetails_ = arg_details\n",
    "arg_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'array1': ['b', 'c'],\n",
       " 'array2': ['d == 2*b', 'e == b+2*c'],\n",
       " 'array3': None,\n",
       " 'return': ['b', 'f == 3 * b']}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_annotations: MetaAnnotations_ = get_meta_annotations(func)\n",
    "meta_annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'b': 4, 'c': 6, 'd': 8, 'e': 10, 'f': 8}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_dict: MetaDict_ = generate_meta_dict(\n",
    "    args_details=arg_details,\n",
    "    meta_annotations=meta_annotations\n",
    ")\n",
    "\n",
    "meta_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test\n",
    "\n",
    "As default, <br/>\n",
    "We get those `comparison expression`s as `MetaAnnotations_`. <br/>\n",
    "To test those expressions, we need the arguments. <br/>\n",
    "The arguments are provided as `MetaDict_`\n",
    "\n",
    "Finally, `test_meta_dict` function tests the expressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'d == 2 * b': True, 'e == b + 2 * c': False, 'f == 3 * b': False}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_result:TestResult_ = test_meta_dict(\n",
    "    meta_dict=meta_dict,\n",
    "    meta_annotations=meta_annotations\n",
    ")\n",
    "\n",
    "test_result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "executable-types-beta",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
